---
AWSTemplateFormatVersion: '2010-09-09'
Description: 'My implementation of AWS EKS with Heptio tutorial. 
Removed bastion host, EKS master is in public subnet, redesign 
network security rules (ACL and SG).'

# The Metadata tells AWS how to display the parameters during stack creation
Metadata:
  AWS::CloudFormation::Interface:
    ParameterGroups:
    - Label:
        default: Required
      Parameters:
#      - AvailabilityZone
      - ApiLbLocation
      - KeyName
      - SSHLocation
    - Label:
        default: Advanced
      Parameters:
      - VPCCIDR
      - PrivateSubnetCIDR
      - PublicSubnetCIDR
      - InstanceType
      - DiskSizeGb
      - QSS3BucketName
      - QSS3KeyPrefix
    - Label:
        default: Kubernetes Configuration
      Parameters:
      - K8sNodeCapacity
      - NetworkingProvider
      - ClusterDNSProvider      

    ParameterLabels:
      VPCCIDR:
        default: VPC CIDR Block
      PrivateSubnetCIDR:
        default: Private Subnet CIDR Block
      PublicSubnetCIDR:
        default: Public Subnet CIDR Block
      KeyName:
        default: SSH Key
#      AvailabilityZone:
#        default: Availability Zone
      InstanceType:
        default: Instance Type
      DiskSizeGb:
        default: Disk Size (GiB)
      K8sNodeCapacity:
        default: Node Capacity
      QSS3BucketName:
        default: S3 Bucket
      QSS3KeyPrefix:
        default: S3 Key Prefix
      NetworkingProvider:
        default: Networking Provider
      ClusterDNSProvider:
        default: Cluster DNS Provider

# The Parameters allow the user to pass custom settings to the stack before creation
Parameters:
  VPCCIDR:
    Description: VPC CIDR Block
    Type: String
    AllowedPattern: "(\\d{1,3})\\.(\\d{1,3})\\.(\\d{1,3})\\.(\\d{1,3})/(\\d{1,2})"
    ConstraintDescription: must be a valid IP CIDR range of the form x.x.x.x/x.
    Default: '10.0.0.0/16'

  PrivateSubnetCIDR:
    Description: CIDR Block for the Private Subnet, must be a valid subnet of the VPC CIDR and not overlap with PublicSubnetCIDR
    Type: String
    AllowedPattern: "(\\d{1,3})\\.(\\d{1,3})\\.(\\d{1,3})\\.(\\d{1,3})/(\\d{1,2})"
    ConstraintDescription: must be a valid IP CIDR range of the form x.x.x.x/x.
    Default: '10.0.0.0/19'

  PublicSubnetCIDR:
    Description: CIDR Block for the Public Subnet, must be a valid subnet of the VPC CIDR and not overlap with PrivateSubnetCIDR
    Type: String
    AllowedPattern: "(\\d{1,3})\\.(\\d{1,3})\\.(\\d{1,3})\\.(\\d{1,3})/(\\d{1,2})"
    ConstraintDescription: must be a valid IP CIDR range of the form x.x.x.x/x.
    Default: '10.0.128.0/20'

  # Specifies the IP range from which you will have SSH access over port 22
  # Used in the allow22 SecurityGroup
  SSHLocation:
    Description: CIDR block (IP address range) to allow SSH access to the
      instances. Use 0.0.0.0/0 to allow access from all locations.
    Type: String
    MinLength: '9'
    MaxLength: '18'
    AllowedPattern: "(\\d{1,3})\\.(\\d{1,3})\\.(\\d{1,3})\\.(\\d{1,3})/(\\d{1,2})"
    ConstraintDescription: must be a valid IP CIDR range of the form x.x.x.x/x.
    Default: '0.0.0.0/0'

  KeyName:
    Description: Existing EC2 KeyPair for SSH access.
    Type: AWS::EC2::KeyPair::KeyName
    ConstraintDescription: must be the name of an existing EC2 KeyPair.

  InstanceType:
    Description: EC2 instance type for the cluster.
    Type: String
    Default: t2.micro
    AllowedValues:
    - t2.micro
    - t2.small
    - t2.medium
    - t3.nano
    - t3.micro
    - t3.small
    - t3.medium
    - m3.medium
    ConstraintDescription: must be a valid Current Generation (non-burstable) EC2 instance type.

  LoadBalancerType:
    Description:  Create Internet-facing (public, external) or Internal-facing Load Balancers
    Type: String
    Default: internet-facing
    AllowedValues: [ "internet-facing", "internal" ]    

  # Specifies the size of the root disk for all EC2 instances, including master
  # and nodes.
  DiskSizeGb:
    Description: 'Size of the root disk for the EC2 instances, in GiB.  Default: 40'
    Default: 40
    Type: Number
    MinValue: 8
    MaxValue: 1024

  # Specifies the IP range from which you will have HTTPS access to the Kubernetes API server load balancer
  # Used in the ApiLoadBalancerSecGroup SecurityGroup
  ApiLbLocation:
    Description: CIDR block (IP address range) to allow HTTPS access to
      the Kubernetes API. Use 0.0.0.0/0 to allow access from all locations.
    Default: '0.0.0.0/0'
    Type: String
    MinLength: '9'
    MaxLength: '18'
    AllowedPattern: "(\\d{1,3})\\.(\\d{1,3})\\.(\\d{1,3})\\.(\\d{1,3})/(\\d{1,2})"
    ConstraintDescription: must be a valid IP CIDR range of the form x.x.x.x/x.

  # Default 2. Choose 1-20 initial nodes to run cluster workloads (in addition to the master node instance)
  # You can scale up your cluster later and add more nodes
  K8sNodeCapacity:
    Default: '2'
    Description: Initial number of Kubernetes nodes (1-20).
    Type: Number
    MinValue: '1'
    MaxValue: '6'
    ConstraintDescription: must be between 1 and 6 EC2 instances.

  # S3 Bucket configuration: allows users to use their own downstream snapshots
  # of the quickstart-aws-vpc and quickstart-linux-bastion templates
  QSS3BucketName:
    AllowedPattern: "^[0-9a-zA-Z]+([0-9a-zA-Z-]*[0-9a-zA-Z])*$"
    ConstraintDescription: Quick Start bucket name can include numbers, lowercase
      letters, uppercase letters, and hyphens (-). It cannot start or end with a hyphen
      (-).

    Default: aws-quickstart
#    Default: testing-k8s-bucket
    Description: Only change this if you have set up assets, like your own networking
      configuration, in an S3 bucket. This and the S3 Key Prefix parameter let you access
      scripts from the scripts/ and templates/ directories of your own fork of the Heptio
      Quick Start assets, uploaded to S3 and stored at
      ${bucketname}.s3.amazonaws.com/${prefix}/scripts/somefile.txt.S3. The bucket name
      can include numbers, lowercase letters, uppercase letters, and hyphens (-).
      It cannot start or end with a hyphen (-).
    Type: String

  QSS3KeyPrefix:
    AllowedPattern: ^[0-9a-zA-Z-/]*$
    ConstraintDescription: Quick Start key prefix can include numbers, lowercase
      letters, uppercase letters, hyphens (-), and forward slash (/).
    Default: quickstart-heptio/
#    Default: dimakievua/  
    Description: Only change this if you have set up assets in an S3 bucket, as explained
      in the S3 Bucket parameter. S3 key prefix for the Quick Start assets.
      Quick Start key prefix can include numbers, lowercase letters, uppercase
      letters, hyphens (-), and forward slash (/).
    Type: String

  NetworkingProvider:
    AllowedValues:
    - calico
    - weave
    ConstraintDescription: 'Currently supported values are "calico" and "weave"'
    Default: calico
    Description: Choose the networking provider to use for communication between
      pods in the Kubernetes cluster. Supported configurations are calico
      (https://docs.projectcalico.org/v2.6/getting-started/kubernetes/installation/hosted/kubeadm/)
      and weave (https://github.com/weaveworks/weave/blob/master/site/kubernetes/kube-addon.md).
    Type: String

  ClusterDNSProvider:
    AllowedValues:
    - CoreDNS
    - KubeDNS
    ConstraintDescription: 'Currently supported values are "CoreDNS" and "KubeDNS"'
    Default: CoreDNS
    Description: Choose the cluster DNS provider to use for internal cluster DNS. Supported
      configurations are CoreDNS and KubeDNS
    Type: String

# http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/mappings-section-structure.html
Mappings:
  # http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html
  RegionMap:
    ap-northeast-1:
      '64': ami-0b877c5e45ebf9c0a
    ap-northeast-2:
      '64': ami-062e8bb4b67e8ad5e
    ap-south-1:
      '64': ami-0851d8bd502a22f42
    ap-southeast-1:
      '64': ami-0dab6dcb940e2995c
    ap-southeast-2:
      '64': ami-0f8ffaadf3dbd5c08
    ca-central-1:
      '64': ami-01a0718639c98c7f3
    eu-central-1:
      '64': ami-0665bc30fa45c8a9b
    eu-west-1:
      '64': ami-071c9dc485a8dd575
    eu-west-2:
      '64': ami-0317f91aee45b8a06
    eu-west-3:
      '64': ami-0728d8b343cbce6c3
    sa-east-1:
      '64': ami-0ed07722477ee4fcc
    us-east-2:
      '64': ami-0aed869d62c92bc4f
    us-west-1:
      '64': ami-02b7bcf98a54651ca
    us-west-2:
      '64': ami-0eae752d5efa34527
    us-east-1:
      '64': ami-0bd4c4f9bd412ef80

Conditions:
  UsEast1Condition:
    Fn::Equals:
    - !Ref AWS::Region
    - "us-east-1"

Resources:
  # Resources for new VPC
  VPC:
    Type: AWS::EC2::VPC
    Properties:
      CidrBlock: !Ref VPCCIDR
      EnableDnsSupport: 'true'
      EnableDnsHostnames: 'true'
      Tags:
      - Key: Name
        Value: !Ref AWS::StackName

  DHCPOptions:
    Type: AWS::EC2::DHCPOptions
    Properties:
      DomainName:
        # us-east-1 needs .ec2.internal, the rest of the regions get <region>.compute.internal.
        # See http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_DHCP_Options.html
        Fn::If:
        - UsEast1Condition
        - "ec2.internal"
        - !Sub "${AWS::Region}.compute.internal"
      DomainNameServers:
      - AmazonProvidedDNS

  VPCDHCPOptionsAssociation:
    Type: AWS::EC2::VPCDHCPOptionsAssociation
    Properties:
      VpcId: !Ref VPC
      DhcpOptionsId: !Ref DHCPOptions

  InternetGateway:
    Type: AWS::EC2::InternetGateway
    Properties:
      Tags:
      - Key: Network
        Value: Public

  VPCGatewayAttachment:
    Type: AWS::EC2::VPCGatewayAttachment
    Properties:
      VpcId: !Ref VPC
      InternetGatewayId: !Ref InternetGateway

  PrivateSubnet:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref VPC
      CidrBlock: !Ref PrivateSubnetCIDR
#      AvailabilityZone: !Ref AvailabilityZone
      AvailabilityZone: !Select 
        - 0
        - Fn::GetAZs: !Ref 'AWS::Region'    
      Tags:
      - Key: Name
        Value: Private subnet
      - Key: Network
        Value: Private

  PublicSubnet:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref VPC
      CidrBlock: !Ref PublicSubnetCIDR
#      AvailabilityZone: !Ref AvailabilityZone
      AvailabilityZone: !Select 
        - 0
        - Fn::GetAZs: !Ref 'AWS::Region'     
      Tags:
      - Key: Name
        Value: Public subnet
      - Key: Network
        Value: Public
      - Key: KubernetesCluster
        Value: !Ref AWS::StackName
      MapPublicIpOnLaunch: true

  # The NAT IP for the private subnet, as seen from within the public one
  NATEIP:
    DependsOn: VPCGatewayAttachment
    Type: AWS::EC2::EIP
    Properties:
      Domain: vpc

  # The NAT gateway for the private subnet
  NATGateway:
    DependsOn: VPCGatewayAttachment
    Type: AWS::EC2::NatGateway
    Properties:
      AllocationId: !GetAtt NATEIP.AllocationId
      SubnetId: !Ref PublicSubnet

  PrivateSubnetRouteTable:
    Type: AWS::EC2::RouteTable
    Properties:
      VpcId: !Ref VPC
      Tags:
      - Key: Name
        Value: Private subnets
      - Key: Network
        Value: Private

  PrivateSubnetRoute:
    DependsOn: VPCGatewayAttachment
    Type: AWS::EC2::Route
    Properties:
      RouteTableId: !Ref PrivateSubnetRouteTable
      DestinationCidrBlock: 0.0.0.0/0
      NatGatewayId: !Ref NATGateway

  PrivateSubnetRouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref PrivateSubnet
      RouteTableId: !Ref PrivateSubnetRouteTable

  PublicSubnetRouteTable:
    Type: AWS::EC2::RouteTable
    Properties:
      VpcId: !Ref VPC
      Tags:
      - Key: Name
        Value: Public Subnets
      - Key: Network
        Value: Public

  PublicSubnetRoute:
    DependsOn: VPCGatewayAttachment
    Type: AWS::EC2::Route
    Properties:
      RouteTableId: !Ref PublicSubnetRouteTable
      DestinationCidrBlock: 0.0.0.0/0
      GatewayId: !Ref InternetGateway

  PublicSubnetRouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref PublicSubnet
      RouteTableId: !Ref PublicSubnetRouteTable      

  ClusterInfoBucket:
    Type: AWS::S3::Bucket
    Properties:
      AccessControl: Private
      Tags:
      - Key: KubernetesCluster
        Value: !Ref AWS::StackName

  # Install a CloudWatch logging group for system logs for each instance
  KubernetesLogGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: !Ref AWS::StackName
      RetentionInDays: 14

  # This is an EC2 instance that will serve as our master node
  K8sMasterInstance:
    Type: AWS::EC2::Instance
    DependsOn: ApiLoadBalancer
    Metadata:
      AWS::CloudFormation::Init:
        configSets:
          master-setup: master-setup
        master-setup:
          files:
            # Script that will allow for development kubernetes binaries to replace the pre-packaged AMI binaries.
            "/tmp/kubernetes-override-binaries.sh":
              source: !Sub "https://${QSS3BucketName}.s3.amazonaws.com/${QSS3KeyPrefix}scripts/kubernetes-override-binaries.sh.in"
              mode: '000755'
              context:
                BaseBinaryUrl: !Sub "https://${QSS3BucketName}.s3.amazonaws.com/${QSS3KeyPrefix}bin/"

            # Configuration file for the cloudwatch agent. The file is a Mustache template, and we're creating it with
            # the below context (mainly to substitute in the AWS Stack Name for the logging group.)
            "/tmp/kubernetes-awslogs.conf":
              source: !Sub "https://${QSS3BucketName}.s3.amazonaws.com/${QSS3KeyPrefix}scripts/kubernetes-awslogs.conf"
              context:
                StackName: !Ref AWS::StackName

            # Installation script for the Cloudwatch agent
            "/usr/local/aws/awslogs-agent-setup.py":
              source: https://s3.amazonaws.com/aws-cloudwatch/downloads/latest/awslogs-agent-setup.py
              mode: '000755'

            # systemd init script for the Cloudwatch logs agent
            "/etc/systemd/system/awslogs.service":
              source: !Sub "https://${QSS3BucketName}.s3.amazonaws.com/${QSS3KeyPrefix}scripts/awslogs.service"

            # setup kubelet hostname
            "/tmp/setup-kubelet-hostname.sh":
              source: !Sub "https://${QSS3BucketName}.s3.amazonaws.com/${QSS3KeyPrefix}scripts/setup-kubelet-hostname.sh"
              mode: '000755'

            # Setup script for initializing the Kubernetes master instance.  This is where most of the cluster
            # initialization happens.  See scripts/setup-k8s-master.sh in the Quick Start repo for details.
            "/tmp/setup-k8s-master.sh":
              source: !Sub "https://${QSS3BucketName}.s3.amazonaws.com/${QSS3KeyPrefix}scripts/setup-k8s-master.sh.in"
              mode: '000755'
              context:
                LoadBalancerDns: !GetAtt ApiLoadBalancer.DNSName
                LoadBalancerName: !Ref ApiLoadBalancer
                ClusterToken: !GetAtt KubeadmToken.Token
                ClusterDNSProvider: !Ref ClusterDNSProvider
                NetworkingProvider: !Ref NetworkingProvider
                NetworkingProviderUrl: !Sub "https://${QSS3BucketName}.s3.amazonaws.com/${QSS3KeyPrefix}scripts/${NetworkingProvider}.yaml"
                DashboardUrl: !Sub "https://${QSS3BucketName}.s3.amazonaws.com/${QSS3KeyPrefix}scripts/dashboard.yaml"
                StorageClassUrl: !Sub "https://${QSS3BucketName}.s3.amazonaws.com/${QSS3KeyPrefix}scripts/default.storageclass.yaml"
                NetworkPolicyUrl: !Sub "https://${QSS3BucketName}.s3.amazonaws.com/${QSS3KeyPrefix}scripts/network-policy.yaml"
                ClusterInfoBucket: !Ref ClusterInfoBucket
                Region: !Ref AWS::Region

            # patch kube proxy
            "/tmp/patch-kube-proxy.sh":
              source: !Sub "https://${QSS3BucketName}.s3.amazonaws.com/${QSS3KeyPrefix}scripts/patch-kube-proxy.sh"
              mode: '000755'

          commands:
            # Override the AMI binaries with any kubelet/kubeadm/kubectl binaries in the S3 bucket
            "00-kubernetes-override-binaries":
              command: "/tmp/kubernetes-override-binaries.sh"
            # Install the Cloudwatch agent with configuration for the current region and log group name
            "01-cloudwatch-agent-setup":
              command: !Sub "python /usr/local/aws/awslogs-agent-setup.py -n -r ${AWS::Region} -c /tmp/kubernetes-awslogs.conf"
            # Enable the Cloudwatch service and launch it
            "02-cloudwatch-service-config":
              command: "systemctl enable awslogs.service && systemctl start awslogs.service"
            # Setup kubelet hostname
            "03-setup-kubelet-hostname":
              command: "/tmp/setup-kubelet-hostname.sh"
            # Run the master setup
            "04-master-setup":
              command: "/tmp/setup-k8s-master.sh"
            "05-patch-kube-proxy":
              command: "/tmp/patch-kube-proxy.sh"
    Properties:
      # Where the EC2 instance gets deployed geographically
#      AvailabilityZone: !Ref AvailabilityZone
#      AvailabilityZone: !Select 
#        - 0
#        - Fn::GetAZs: !Ref 'AWS::Region'
      AvailabilityZone: !GetAtt  PublicSubnet.AvailabilityZone 
      # Refers to the MasterInstanceProfile resource, which applies the IAM role for the master instance
      # The IAM role allows us to create further AWS resources (like an EBS drive) from the cluster
      # This is needed for the Kubernetes-AWS cloud-provider integration
      IamInstanceProfile: !Ref MasterInstanceProfile
      # Type of instance; the default is m3.medium
      InstanceType: !Ref InstanceType
      # Adds our SSH key to the instance
      KeyName: !Ref KeyName
      NetworkInterfaces:
      - DeleteOnTermination: true
        DeviceIndex: 0
        #SubnetId: !Ref PrivateSubnet
        SubnetId: !Ref PublicSubnet
        # Joins the ClusterSecGroup Security Group for cluster communication and SSH access
        # The ClusterSecGroupCrossTalk rules allow all instances in the same stack to communicate internally
        # The ClusterSecGroupAllow22 rules allow external communication on port 22 from a chosen CIDR range
        # The ClusterSecGroupAllow6443FromLB rules allow HTTPS access to the load balancer on port 6443
        GroupSet:
        - !Ref ClusterSecGroup
      # Designates a name for this EC2 instance that will appear in the instances list (k8s-master)
      # Tags it with KubernetesCluster=<stackname> or chosen value (needed for cloud-provider's IAM roles)
      Tags:
      - Key: Name
        Value: k8s-master
      - Key: KubernetesCluster
        Value: !Ref AWS::StackName
        # Also tag it with kubernetes.io/cluster/clustername=owned, which is the newer convention for cluster resources
      - Key: !Sub 'kubernetes.io/cluster/${AWS::Region}'        
        Value: 'owned'
      # http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-instance.html#cfn-ec2-instance-imageid
      ImageId:
        Fn::FindInMap:
        - RegionMap
        - !Ref AWS::Region
        - '64'
      BlockDeviceMappings:
      - DeviceName: '/dev/sda1'
        Ebs:
          VolumeSize: !Ref DiskSizeGb
          VolumeType: gp2
      # The userdata script is launched on startup, but contains only the commands that call out to cfn-init, which runs
      # the commands in the metadata above, and cfn-signal, which signals when the initialization is complete.
      # Removed #              --exit-code $? \ for test
      UserData:
        Fn::Base64:
          Fn::Sub: |
            #!/bin/bash
            set -o xtrace

            CFN_INIT=$(which cfn-init)
            CFN_SIGNAL=$(which cfn-signal)

            ${!CFN_INIT} \
              --verbose \
              --stack '${AWS::StackName}' \
              --region '${AWS::Region}' \
              --resource K8sMasterInstance \
              --configsets master-setup

            ${!CFN_SIGNAL} \
              --success true \
              --stack '${AWS::StackName}' \
              --region '${AWS::Region}' \
              --resource K8sMasterInstance
    CreationPolicy:
      ResourceSignal:
        Timeout: PT10M

  # IAM role for Lambda function for generating kubeadm token
  LambdaExecutionRole:
    Type: "AWS::IAM::Role"
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
        - Effect: "Allow"
          Principal:
            Service: ["lambda.amazonaws.com"]
          Action: "sts:AssumeRole"
      Path: "/"
      Policies:
      - PolicyName: "lambda_policy"
        PolicyDocument:
          Version: "2012-10-17"
          Statement:
          - Effect: "Allow"
            Action:
            - "logs:CreateLogGroup"
            - "logs:CreateLogStream"
            - "logs:PutLogEvents"
            Resource: "arn:aws:logs:*:*:*"

  # Lambda Function for generating the kubeadm token
  GenKubeadmToken:
    Type: "AWS::Lambda::Function"
    Properties:
      Code:
        ZipFile: |
          import random
          import string
          import cfnresponse
          def id_generator(size, chars=string.ascii_lowercase + string.digits):
            return ''.join(random.choice(chars) for _ in range(size))
          def handler(event, context):
            if event['RequestType'] == 'Delete':
              cfnresponse.send(event, context, cfnresponse.SUCCESS, {})
            if event['RequestType'] == 'Create':
              token = ("%s.%s" % (id_generator(6), id_generator(16)))
              responseData = {}
              responseData['Token'] = token
              cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData)
              return token
      Handler: "index.handler"
      Runtime: "python2.7"
      Timeout: "5"
      Role: !GetAtt LambdaExecutionRole.Arn

  # A Custom resource that uses the lambda function to generate our cluster token
  KubeadmToken:
    Type: "Custom::GenerateToken"
    Version: "1.0"
    Properties:
      ServiceToken: !GetAtt GenKubeadmToken.Arn

  # This is a CloudWatch alarm https://aws.amazon.com/cloudwatch/
  # If the master node is unresponsive for 5 minutes, AWS will attempt to recover it
  # It will preserve the original IP, which is important for Kubernetes networking
  # Based on http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/quickref-cloudwatch.html#cloudwatch-sample-recover-instance
  RecoveryTestAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmDescription: Trigger a recovery when instance status check fails for 5
        consecutive minutes.
      Namespace: AWS/EC2
      MetricName: StatusCheckFailed_System
      Statistic: Minimum
      # 60-second periods (1 minute)
      Period: '60'
      # 5-minute check-ins
      EvaluationPeriods: '5'
      ComparisonOperator: GreaterThanThreshold
      Threshold: '0'
      # This is the call that actually tries to recover the instance
      AlarmActions:
        - !Sub "arn:aws:automate:${AWS::Region}:ec2:recover"
      # Applies this alarm to our K8sMasterInstance
      Dimensions:
      - Name: InstanceId
        Value: !Ref K8sMasterInstance

  # This is the Auto Scaling Group that contains EC2 instances that are Kubernetes nodes
  # http://docs.aws.amazon.com/autoscaling/latest/userguide/AutoScalingGroup.html
  K8sNodeGroup:
    Type: AWS::AutoScaling::AutoScalingGroup
    DependsOn: K8sMasterInstance
    CreationPolicy:
      ResourceSignal:
        # Ensure at least <K8sNodeCapacity> nodes have signaled success before
        # this resource is considered created.
        Count: !Ref K8sNodeCapacity
        Timeout: PT10M
    Properties:
      # Where the EC2 instance gets deployed geographically
#      AvailabilityZones:
#      - !Ref AvailabilityZone
#      AvailabilityZone: !Select 
#        - 0
#        - Fn::GetAZs: !Ref 'AWS::Region'    
      AvailabilityZones: 
        - !GetAtt  PrivateSubnet.AvailabilityZone               
      # Refers to the K8sNodeCapacity parameter, which specifies the number of nodes (1-20)
      DesiredCapacity: !Ref K8sNodeCapacity
      # Refers to the LaunchConfig, which has specific config details for the EC2 instances
      LaunchConfigurationName: !Ref LaunchConfig
      # More cluster sizing
      MinSize: '1'
      MaxSize: '20'
      # VPC Zone Identifier is the subnets to put the hosts in
      VPCZoneIdentifier:     
      - !Ref PrivateSubnet 
      # Designates names for these EC2 instances that will appear in the instances list (k8s-node)
      # Tags each node with KubernetesCluster=<stackname> or chosen value (needed for cloud-provider's IAM roles)
      Tags:
      - Key: Name
        Value: k8s-node
        PropagateAtLaunch: 'true'
      - Key: KubernetesCluster
        Value: !Ref AWS::StackName
        PropagateAtLaunch: 'true'
        # Also tag it with kubernetes.io/cluster/clustername=owned, which is the newer convention for cluster resources
      - Key: !Sub 'kubernetes.io/cluster/${AWS::Region}'
        Value: 'owned'
        PropagateAtLaunch: 'true'
    # Tells the group how many instances to update at a time, if an update is applied
    UpdatePolicy:
      AutoScalingRollingUpdate:
        MinInstancesInService: '1'
        MaxBatchSize: '1'

  # This tells AWS what kinds of servers we want in our Auto Scaling Group
  LaunchConfig:
    Type: AWS::AutoScaling::LaunchConfiguration
    Metadata:
      AWS::CloudFormation::Init:
        configSets:
          node-setup: node-setup
        node-setup:
          # (See comments in the master instance Metadata for details.)
          files:
            "/tmp/kubernetes-override-binaries.sh":
              source: !Sub "https://${QSS3BucketName}.s3.amazonaws.com/${QSS3KeyPrefix}scripts/kubernetes-override-binaries.sh.in"
              mode: '000755'
              context:
                BaseBinaryUrl: !Sub "https://${QSS3BucketName}.s3.amazonaws.com/${QSS3KeyPrefix}bin/"
            "/tmp/kubernetes-awslogs.conf":
              source: !Sub "https://${QSS3BucketName}.s3.amazonaws.com/${QSS3KeyPrefix}scripts/kubernetes-awslogs.conf"
              context:
                StackName: !Ref AWS::StackName
            "/usr/local/aws/awslogs-agent-setup.py":
              source: https://s3.amazonaws.com/aws-cloudwatch/downloads/latest/awslogs-agent-setup.py
              mode: '000755'
            "/etc/systemd/system/awslogs.service":
              source: !Sub "https://${QSS3BucketName}.s3.amazonaws.com/${QSS3KeyPrefix}scripts/awslogs.service"
            "/tmp/setup-kubelet-hostname.sh":
              source: !Sub "https://${QSS3BucketName}.s3.amazonaws.com/${QSS3KeyPrefix}scripts/setup-kubelet-hostname.sh"
              mode: '000755'
            "/tmp/setup-k8s-node.sh":
              mode: '000755'
              source: !Sub "https://${QSS3BucketName}.s3.amazonaws.com/${QSS3KeyPrefix}scripts/setup-k8s-node.sh.in"
              context:
                K8sMasterPrivateIp: !GetAtt K8sMasterInstance.PrivateIp
                ClusterToken: !GetAtt KubeadmToken.Token
                ClusterInfoBucket: !Ref ClusterInfoBucket

          commands:
            "00-kubernetes-override-binaries":
              command: "/tmp/kubernetes-override-binaries.sh"
            "01-cloudwatch-agent-setup":
              command: !Sub "python /usr/local/aws/awslogs-agent-setup.py -n -r ${AWS::Region} -c /tmp/kubernetes-awslogs.conf"
            "02-cloudwatch-service-config":
              command: "systemctl enable awslogs.service && systemctl start awslogs.service"
            "03-setup-kubelet-hostname":
              command: "/tmp/setup-kubelet-hostname.sh"
#            "04-k8s-setup-node":
#              command: "/tmp/setup-k8s-node.sh"
    Properties:
      # Refers to the NodeInstanceProfile resource, which applies the IAM role for the nodes
      # The IAM role allows us to create further AWS resources (like an EBS drive) from the cluster
      # This is needed for the Kubernetes-AWS cloud-provider integration
      IamInstanceProfile: !Ref NodeInstanceProfile
      # http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-instance.html#cfn-ec2-instance-imageid
      ImageId:
        Fn::FindInMap:
        - RegionMap
        - !Ref AWS::Region
        - '64'
      BlockDeviceMappings:
      - DeviceName: '/dev/sda1'
        Ebs:
          VolumeSize: !Ref DiskSizeGb
          VolumeType: gp2
      # Type of instance; the default is m3.medium
      InstanceType: !Ref InstanceType
      # Adds our SSH key to the instance
      KeyName: !Ref KeyName
      # Join the cluster security group so that we can customize the access
      # control (See the ClusterSecGroup resource for details)
      SecurityGroups:
      - !Ref ClusterSecGroup
      # The userdata script is launched on startup, but contains only the commands that call out to cfn-init, which runs
      # the commands in the metadata above, and cfn-signal, which signals when the initialization is complete.
      UserData:
        Fn::Base64:
          Fn::Sub: |
            #!/bin/bash
            set -o xtrace

            /usr/local/bin/cfn-init \
              --verbose \
              --stack '${AWS::StackName}' \
              --region '${AWS::Region}' \
              --resource LaunchConfig \
              --configsets node-setup

            /usr/local/bin/cfn-signal \
              --exit-code $? \
              --stack '${AWS::StackName}' \
              --region '${AWS::Region}' \
              --resource K8sNodeGroup

  # Define the (one) security group for all machines in the cluster.  Keeping
  # just one security group helps with k8s's cloud-provider=aws integration so
  # that it knows what security group to manage.
  ClusterSecGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Security group for all machines in the cluster
      VpcId: !Ref VPC
      # Security Groups must be tagged with KubernetesCluster=<cluster> so that
      # they can coexist in the same VPC
      Tags:
      - Key: KubernetesCluster
        Value: !Ref AWS::StackName          
      - Key: !Sub 'kubernetes.io/cluster/${AWS::Region}'
        Value: 'owned'
      - Key: Name
        Value: k8s-cluster-security-group

  # Permissions we add to the main security group:
  # - Ensure cluster machines can talk to one another
  ClusterSecGroupCrossTalk:
    Type: AWS::EC2::SecurityGroupIngress
    Properties:
      GroupId: !Ref ClusterSecGroup
      SourceSecurityGroupId: !Ref ClusterSecGroup
      IpProtocol: '-1'
      FromPort: '0'
      ToPort: '65535'

  # - Open up port 22 for SSH into each machine
  # The allowed locations are chosen by the user in the SSHLocation parameter
  ClusterSecGroupAllow22:
    Metadata:
      Comment: Open up port 22 for SSH into each machine
    Type: AWS::EC2::SecurityGroupIngress
    Properties:
      GroupId: !Ref ClusterSecGroup
      IpProtocol: tcp
      FromPort: '22'
      ToPort: '22'
      CidrIp: !Ref SSHLocation

  # Allow the apiserver load balancer to talk to the cluster on port 6443
  ClusterSecGroupAllow6443FromLB:
    Metadata:
      Comment: Open up port 6443 for load balancing the API server
    Type: AWS::EC2::SecurityGroupIngress
    Properties:
      GroupId: !Ref ClusterSecGroup
      IpProtocol: tcp
      FromPort: '6443'
      ToPort: '6443'
      SourceSecurityGroupId: !Ref ApiLoadBalancerSecGroup

  # IAM role for nodes http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html
  NodeRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service:
            - ec2.amazonaws.com
          Action:
          - sts:AssumeRole
      Path: "/"
      # IAM policy for nodes that allows specific AWS resource listing and creation
      # http://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html
      Policies:
      - PolicyName: node
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: Allow
            Action:
            - ec2:Describe*
            - ecr:GetAuthorizationToken
            - ecr:BatchCheckLayerAvailability
            - ecr:GetDownloadUrlForLayer
            - ecr:GetRepositoryPolicy
            - ecr:DescribeRepositories
            - ecr:ListImages
            - ecr:BatchGetImage
            Resource: "*"

      - PolicyName: cwlogs
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: Allow
            Action:
            - logs:CreateLogGroup
            - logs:CreateLogStream
            - logs:PutLogEvents
            - logs:DescribeLogStreams
            Resource: !Sub ["${LogGroupArn}:*", LogGroupArn: !GetAtt KubernetesLogGroup.Arn]

      - PolicyName: discoverBucketWrite
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: Allow
            Action:
            - s3:GetObject
            Resource: !Sub "arn:aws:s3:::${ClusterInfoBucket}/cluster-info.yaml"

  # Resource that creates the node IAM role
  NodeInstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      Path: "/"
      Roles:
      - !Ref NodeRole

  # IAM role for the master node http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html
  MasterRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service:
            - ec2.amazonaws.com
          Action:
          - sts:AssumeRole
      Path: "/"
      # IAM policy for the master node that allows specific AWS resource listing and creation
      # More permissive than the node role (it allows load balancer creation)
      # http://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html
      Policies:
      - PolicyName: master
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: Allow
            Action:
            - ec2:*
            - elasticloadbalancing:*
            - ecr:GetAuthorizationToken
            - ecr:BatchCheckLayerAvailability
            - ecr:GetDownloadUrlForLayer
            - ecr:GetRepositoryPolicy
            - ecr:DescribeRepositories
            - ecr:ListImages
            - ecr:BatchGetImage
            - autoscaling:DescribeAutoScalingGroups
            - autoscaling:UpdateAutoScalingGroup
            Resource: "*"

      - PolicyName: cwlogs
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: Allow
            Action:
            - logs:CreateLogGroup
            - logs:CreateLogStream
            - logs:PutLogEvents
            - logs:DescribeLogStreams
            Resource: !Sub ["${LogGroupArn}:*", LogGroupArn: !GetAtt KubernetesLogGroup.Arn]

      - PolicyName: discoverBucketWrite
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: Allow
            Action:
            - s3:PutObject
            Resource: !Sub "arn:aws:s3:::${ClusterInfoBucket}/cluster-info.yaml"

  # Bind the MasterRole to a profile for the VM instance.
  MasterInstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      Path: "/"
      Roles:
      - !Ref MasterRole

  # Create a placeholder load balancer for the API server. Backend instances will be added by the master itself on the
  # first boot in the startup script above. The load balancer listens on both port 443 and 6443. 
  # The port 6443 is the api port specified in kubeadm init and it's used by clients to connet to the master.
  ApiLoadBalancer:
    Type: AWS::ElasticLoadBalancing::LoadBalancer
    Properties:
      Scheme: !Ref LoadBalancerType
      Listeners:
      - Protocol: TCP
        InstancePort: 6443
        InstanceProtocol: TCP
        LoadBalancerPort: 443
      - Protocol: TCP
        InstancePort: 6443
        InstanceProtocol: TCP
        LoadBalancerPort: 6443
      HealthCheck:
        Target: TCP:6443
        HealthyThreshold: '3'
        UnhealthyThreshold: '2'
        Interval: '10'
        Timeout: '5'
      ConnectionSettings:
        IdleTimeout: 3600
      Subnets:
      - !Ref PublicSubnet
      SecurityGroups:
      - !Ref ApiLoadBalancerSecGroup
      Tags:
      - Key: KubernetesCluster
        Value: !Ref AWS::StackName
      - Key: !Sub 'kubernetes.io/cluster/${AWS::Region}'
        Value: 'owned'
      - Key: 'kubernetes.io/service-name'
        Value: 'kube-system/apiserver-public'

  # Security group to allow public access to port 443 and 6443
  ApiLoadBalancerSecGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Security group for API server load balancer
      VpcId: !Ref VPC
      SecurityGroupIngress:
      - CidrIp: !Ref ApiLbLocation
        FromPort: 443
        ToPort: 443
        IpProtocol: tcp
      - CidrIp: !Ref ApiLbLocation
        FromPort: 6443
        ToPort: 6443
        IpProtocol: tcp
      Tags:
      - Key: Name
        Value: apiserver-lb-security-group

  # Give the cleanup lambda function the necessary policy.
  CleanupClusterInfoRole:
    Type: "AWS::IAM::Role"
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
        - Effect: "Allow"
          Principal:
            Service: ["lambda.amazonaws.com"]
          Action: "sts:AssumeRole"
      Path: "/"
      Policies:
      - PolicyName: s3upload
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: Allow
            Action:
            - logs:CreateLogGroup
            - logs:CreateLogStream
            - logs:PutLogEvents
            Resource: arn:aws:logs:*:*:*
          - Effect: Allow
            Action: ['s3:DeleteObject']
            Resource: [!Sub "arn:aws:s3:::${ClusterInfoBucket}/cluster-info.yaml"]

  # CleanupClusterInfo backs the custom resource defined below.
  # When the custom resource gets created, deleted or updated this function will be executed.
  CleanupClusterInfo:
    Type: "AWS::Lambda::Function"
    Properties:
      Code:
        ZipFile:
          Fn::Sub: |
            import boto3
            import cfnresponse

            def lambda_handler(event, context):
                try:
                    s3 = boto3.client('s3')
                    bucket = '${ClusterInfoBucket}'
                    key = 'cluster-info.yaml'

                    if event['RequestType'] == 'Delete':
                        s3.delete_object(Bucket=bucket, Key=key)

                    cfnresponse.send(event, context, cfnresponse.SUCCESS, {})
                    return
                except Exception as e:
                    print(e)
                cfnresponse.send(event, context, cfnresponse.FAILED, {})
      Handler: "index.lambda_handler"
      Runtime: "python3.6"
      Timeout: "5"
      Role: !GetAtt CleanupClusterInfoRole.Arn

  CleanupClusterInfoOnDelete:
    Type: "Custom::CleanupClusterInfo"
    Properties:
      ServiceToken: !GetAtt CleanupClusterInfo.Arn

# Outputs are what AWS will show you after stack creation
# Generally they let you easily access some information about the stack
# like what IP address is assigned to your master node
# Read Descriptions below for more detail
Outputs:
  # Outputs from VPC creation
  VPCID:
    Description: ID of the newly-created EC2 VPC.
    Value: !Ref VPC

  MasterInstanceId:
    Description: InstanceId of the master EC2 instance.
    Value: !Ref K8sMasterInstance

  MasterPrivateIp:
    Description: Private IP address of the master.
    Value: !GetAtt K8sMasterInstance.PrivateIp

  NodeGroupInstanceId:
    Description: InstanceId of the newly-created NodeGroup.
    Value: !Ref K8sNodeGroup

  JoinNodes:
    Description: Command to join more nodes to this cluster.
    Value: !Sub "aws s3 cp s3://${ClusterInfoBucket}/cluster-info.yaml /tmp/cluster-info.yaml && kubeadm join --node-name=\"$(hostname -f 2>/dev/null || curl http://169.254.169.254/latest/meta-data/local-hostname)\" --token=${KubeadmToken.Token} --discovery-file=/tmp/cluster-info.yaml ${K8sMasterInstance.PrivateIp}:6443"

  NextSteps:
    Description: Verify your cluster and deploy a test application. Instructions -
      http://jump.heptio.com/aws-qs-next
    Value: http://jump.heptio.com/aws-qs-next

#  GetKubeConfigCommand:
#    Description: Run locally - SCP command to download the Kubernetes configuration
#      file for accessing the new cluster via kubectl, a Kubernetes command line tool.
#      Creates a "kubeconfig" file in the current directory. Then, you can run
#      "export KUBECONFIG=$(pwd)/kubeconfig" to ensure kubectl uses this configuration file.
#      About kubectl - https://kubernetes.io/docs/user-guide/prereqs/
#    Value: !Sub >-
#      SSH_KEY="path/to/${KeyName}.pem";
#      scp
#      -i $SSH_KEY
#      -o ProxyCommand="ssh -i \"${!SSH_KEY}\" ubuntu@${BastionHost.PublicIp} nc %h %p"
#      ubuntu@${K8sStack.Outputs.MasterPrivateIp}:~/kubeconfig ./kubeconfig